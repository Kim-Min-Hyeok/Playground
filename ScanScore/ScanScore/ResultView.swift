//
//  ResultView.swift
//  ScanScore
//
//  Created by Minhyeok Kim on 1/28/25.
//

import SwiftUI
import PhotosUI

struct ResultView: View {
    @State private var selectedImage: UIImage?
    @State private var processedImage: UIImage?
    @State private var staves: [NSNumber] = [] // ì˜¤ì„  ì¢Œí‘œ ì €ìž¥
    @State private var detectedObjects: [NSDictionary] = []
    @State private var isPickerPresented = false
    let standardSpacing: CGFloat = 10.0  // ê¸°ì¤€ ì˜¤ì„  ê°„ê²©
    
    var body: some View {
        VStack {
            if let image = processedImage ?? selectedImage {
                Image(uiImage: image)
                    .resizable()
                    .scaledToFit()
                    .frame(height: 600)
            } else {
                Text("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                    .font(.headline)
            }
            
            HStack {
                Button("ì•¨ë²”ì—ì„œ ì´ë¯¸ì§€ ì„ íƒ") {
                    isPickerPresented = true
                }
                .padding()
                .sheet(isPresented: $isPickerPresented) {
                    PhotoPicker(selectedImage: $selectedImage)
                }
                
                Button("OpenCV - ì´ì§„í™”") {
                    if let image = selectedImage {
                        processedImage = PreProcessing.threshold(image)
                    }
                }
                .padding()
                
                Button("OpenCV - ë³´í‘œ ì¶”ì¶œ") {
                    if let image = selectedImage {
                        processedImage = PreProcessing.removeNoise(image)
                    }
                }
                .padding()
                
                Button("OpenCV - ì˜¤ì„  ì œê±°") {
                    if let image = processedImage {
                        var stavesArray: NSArray = [] // âœ… NSArrayë¡œ ì„ ì–¸
                        processedImage = PreProcessing.removeStaves(image, staves: &stavesArray)

                        if let convertedStaves = stavesArray as? [NSNumber] { // âœ… Swift ë°°ì—´ë¡œ ë³€í™˜
                            staves = convertedStaves
                            print("[DEBUG] ê²€ì¶œëœ ì˜¤ì„  ê°œìˆ˜: \(staves.count)")
                        } else {
                            print("[ERROR] ì˜¤ì„  ê°ì§€ ì‹¤íŒ¨: staves ë³€í™˜ ì˜¤ë¥˜")
                        }
                    }
                }
                .padding()

                Button("OpenCV - ì•…ë³´ ì •ê·œí™”") {
                    if let image = processedImage, !staves.isEmpty {
                        processedImage = PreProcessing.normalizeImage(image, staves: staves, standard: standardSpacing)
                    } else {
                        print("[ERROR] ì•…ë³´ ì •ê·œí™” ì‹¤íŒ¨: ì˜¤ì„  ì¢Œí‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    }
                }
                .padding()
                
                Button("OpenCV - ê°ì²´ ê²€ì¶œ") {
                    if let image = processedImage {
                        if let result = ObjectDetection.detectObjects(image, staves: staves) as? [String: Any],
                           let updatedImage = result["image"] as? UIImage,
                           let detectedObjectsArray = result["objects"] as? [NSDictionary] {
                            processedImage = updatedImage
                            detectedObjects = detectedObjectsArray
                            print("[DEBUG] ê²€ì¶œëœ ê°ì²´ ê°œìˆ˜: \(detectedObjects.count)")
                        } else {
                            print("[ERROR] ê°ì²´ ê²€ì¶œ ì‹¤íŒ¨")
                        }
                    }
                }
                
                Button("OpenCV - ê°ì²´ ë¶„ì„") {
                    if let image = processedImage {
                        print("[DEBUG] ê°ì²´ ë¶„ì„ ì‹œìž‘")
                        // NSDictionaryë¥¼ [AnyHashable: Any]ë¡œ ë³€í™˜
                        let convertedObjects: [[AnyHashable: Any]] = detectedObjects.map { $0 as? [AnyHashable: Any] ?? [:] }
                        processedImage = ObjectAnalysis.analyzeObjects(image, objects: convertedObjects)
                    }
                }
                .padding()
                
                Button("OpenCV - ì¡°í‘œ ì¸ì‹") {
                    if let image = processedImage {
                        let convertedObjects: [[AnyHashable: Any]] = detectedObjects.map { $0 as? [AnyHashable: Any] ?? [:] }
                        processedImage = ObjectRecognition.recognition(image, staves: staves, objects: convertedObjects)
                    }
                }
                .padding()
            }
        }
    }
}

// ðŸ“Œ `PhotoPicker` ë·° ì¶”ê°€: ì‚¬ì§„ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì´ë¯¸ì§€ ì„ íƒ
struct PhotoPicker: UIViewControllerRepresentable {
    @Binding var selectedImage: UIImage?
    
    func makeCoordinator() -> Coordinator {
        Coordinator(self)
    }
    
    func makeUIViewController(context: Context) -> PHPickerViewController {
        var config = PHPickerConfiguration()
        config.filter = .images
        config.selectionLimit = 1
        
        let picker = PHPickerViewController(configuration: config)
        picker.delegate = context.coordinator
        return picker
    }
    
    func updateUIViewController(_ uiViewController: PHPickerViewController, context: Context) {}
    
    class Coordinator: NSObject, PHPickerViewControllerDelegate {
        let parent: PhotoPicker
        
        init(_ parent: PhotoPicker) {
            self.parent = parent
        }
        
        func picker(_ picker: PHPickerViewController, didFinishPicking results: [PHPickerResult]) {
            picker.dismiss(animated: true)
            
            if let provider = results.first?.itemProvider, provider.canLoadObject(ofClass: UIImage.self) {
                provider.loadObject(ofClass: UIImage.self) { image, _ in
                    DispatchQueue.main.async {
                        self.parent.selectedImage = image as? UIImage
                    }
                }
            }
        }
    }
}

#Preview {
    ResultView()
}
